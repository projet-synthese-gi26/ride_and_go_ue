# ===================================================================
# PRODUCTION CONFIGURATION - RIDE & GO API
# ===================================================================

server:
  port: 8080
  error:
    include-message: always # Useful for frontend debugging

spring:
  application:
    name: ride-and-go

  datasource:
    url: jdbc:postgresql://${DB_HOST:168.119.122.86}:${DB_PORT:5432}/${DB_NAME:yowyob}?currentSchema=ride_and_go
    username: ${DB_USERNAME:master}
    password: ${DB_PASSWORD:Azerty1234*}
    driver-class-name: org.postgresql.Driver

  liquibase:
    user: ${DB_USERNAME:master}
    password: ${DB_PASSWORD:Azerty1234*}
    enabled: true
    change-log: classpath:db/changelog/db.changelog-master.yaml
    default-schema: ride_and_go
    liquibase-schema: ride_and_go
    url: jdbc:postgresql://${DB_HOST:168.119.122.86}:${DB_PORT:5432}/${DB_NAME:yowyob}


  # DATABASE CONFIGURATION (REACTIVE R2DBC)
  r2dbc:
    url: r2dbc:postgresql://${DB_HOST:168.119.122.86}:${DB_PORT:5432}/${DB_NAME:yowyob}?schema=ride_and_go
    username: ${DB_USERNAME:master}
    password: ${DB_PASSWORD:Azerty1234*}
    pool:
      enabled: true
      initial-size: 5
      max-size: 20
      max-idle-time: 30m
      validation-query: SELECT 1

  # CRITICAL SECURITY: Never run local scripts on production server
  sql:
    init:
      mode: never

  # REDIS CACHE (CLUSTER MODE)
  data:
    redis:
      password: ${REDIS_PASSWORD:Azerty1234*}
      cluster:
        nodes:
          - ${REDIS_HOST:168.119.122.86}:7001
          - ${REDIS_HOST:168.119.122.86}:7002
          - ${REDIS_HOST:168.119.122.86}:7003

  # MESSAGING SYSTEM (KAFKA)
  kafka:
    bootstrap-servers: ${KAFKA_HOST:168.119.122.86}:${KAFKA_PORT:9092}
    consumer:
      group-id: ride-and-go-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

# CUSTOM BUSINESS SERVICES CONFIGURATION
application:

  auth:
    mode: remote # 'fake' pour ton dev local, 'remote' pour le serveur réel
    url: https://auth-service.pynfi.com

  fare:
    mode: remote # 'fake' pour ton dev local, 'remote' pour le serveur réel
    url: https://fare-calculator-service.pynfi.com
    api-key: 974e9428-6ce2-48e7-b74b-93f572007ef8

  notification:
    mode: http
    url: https://notification-service.pynfi.com
    service-token: ${NOTIFICATION_SERVICE_TOKEN}
    templates:
      new-offer: 1        # ID template: Nouvelle offre pour les chauffeurs
      driver-applied: 2   # ID template: Un chauffeur a postulé (pour le client)
      driver-selected: 3  # ID template: Vous avez été choisi (pour le chauffeur)
      ride-confirmed: 4   # ID template: Le chauffeur arrive (pour le client)
      ride-cancelled: 5   # ID template: Course annulée
      admin-validation: 7 # ID template: admin a validé le profil du driver

  vehicle:
    url: https://vehicule-service.pynfi.com

  kafka:
    topics:
      notification-service-create-topic: notification-create-topic
      offer-created: offer-created-topic
      offer-send: notification-send-topic
    notification-registration:
      name: "Ride and Go"
      email:
        host: ${SMTP_HOST:smtp.gmail.com}
        port: ${SMTP_PORT:587}
        username: ${SMTP_USERNAME}
        password: ${SMTP_PASSWORD}
    notification-service:
      token: token-topic
      template:
        new-offer-id: 1001
        accepted-offer-id: 1002

# MONITORING & HEALTH CHECK (ACTUATOR)
management:
  endpoints:
    web:
      exposure:
        include: ["health", "info", "prometheus"]
  endpoint:
    health:
      show-details: "always"
      probes:
        enabled: true
  metrics:
    export:
      prometheus:
        enabled: true

# ======================================================
# 2. CONFIGURATION TIMEOUT (Resilience4j)
# ======================================================
resilience4j:
  circuitbreaker:
    instances:
      # Config pour le service de prix
      fare-calculator-service:
        failureRateThreshold: 50
        waitDurationInOpenState: 10s
        slidingWindowSize: 10
        permittedNumberOfCallsInHalfOpenState: 3
      # Config pour le service auth (si besoin)
      auth-service:
        failureRateThreshold: 50
        waitDurationInOpenState: 5s
        slidingWindowSize: 5

  # C'est ici qu'on règle le problème "Did not observe any item... within 1000ms"
  timelimiter:
    instances:
      fare-calculator-service:
        timeoutDuration: 20s  
      auth-service:
        timeoutDuration: 20s
